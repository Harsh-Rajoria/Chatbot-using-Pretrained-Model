# Chatbot-using-Pretrained-Model
# ğŸ’¬ ChatBuddy - Personal AI Chatbot

ChatBuddy is a friendly AI-powered conversational assistant built with **FastAPI** (backend) and **Streamlit** (frontend).  
It uses the **facebook/blenderbot-400M-distill** model from Hugging Face to generate human-like, engaging, and context-aware conversations â€” just like ChatGPT but lightweight and CPU-friendly.

---

## ğŸš€ Features

- ğŸ¤– Conversational AI using **BlenderBot-400M-distill**
- ğŸ’¡ Context-aware chat history between user and ChatBuddy
- ğŸ§  Friendly persona for casual, educational, and fun interactions
- ğŸŒ Backend built with **FastAPI**
- ğŸ¨ Frontend built with **Streamlit**
- âš¡ Works smoothly even on CPU (no GPU required)
- ğŸ§© Easy to deploy on Railway, Render, or Hugging Face Spaces

---

## ğŸ§© Project Structue

chatbot/
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py              # Streamlit user interface
â”‚   â”œâ”€â”€ requirements.txt    # Frontend dependencies
â”‚   â””â”€â”€ README.md           # Documentation file (this one)
â”‚
â””â”€â”€ backend/
â”œâ”€â”€ server.py           # FastAPI backend with Hugging Face model
â”œâ”€â”€ requirements.txt    # Backend dependencies
â””â”€â”€ Procfile            # Deployment configuration (optional)

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/chatbuddy.git
cd chatbot

2ï¸âƒ£ Backend Setup
cd backend
pip install -r requirements.txt
uvicorn server:app --reload

Your backend API will start at:
http://127.0.0.1:8000

3ï¸âƒ£ Frontend Setup
open a terminal window
cd frontend
pip install -r requirements.txt
streamlit run app.py

Your frontend will start at:
http://localhost:8501

